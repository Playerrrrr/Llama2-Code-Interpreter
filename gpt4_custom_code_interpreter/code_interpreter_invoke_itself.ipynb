{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import requests \n",
    "import numpy as np \n",
    "from retrying import retry\n",
    "from typing import List, Optional, Union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install and import basic package for GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: bs4 in /opt/homebrew/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: wikipedia in /opt/homebrew/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: sqlalchemy in /opt/homebrew/lib/python3.11/site-packages (2.0.18)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from bs4) (4.11.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from wikipedia) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.11/site-packages (from sqlalchemy) (4.7.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/sip/6.7.9/libexec/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from beautifulsoup4->bs4) (2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/seungyounshin/Library/Python/3.11/lib/python/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pandas bs4 wikipedia sqlalchemy torch matplotlib\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipedia\n",
    "import os,sys,pathlib\n",
    "import cv2\n",
    "import datetime\n",
    "import sqlalchemy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import logging\n",
    "from termcolor import colored\n",
    "# load from key file\n",
    "with open('./rilab_key.txt') as f:\n",
    "    OPENAI_API_KEY = key = f.read()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTChat Class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTChatClass:\n",
    "    def __init__(self, model=\"gpt-4\", role_msg = 'You are a helpful assistant.'):\n",
    "        self.model = model\n",
    "        self.messages = [{\"role\": \"system\", \"content\": f'{role_msg}'}]  # initial system message\n",
    "        self.response = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        if not role or not content:\n",
    "            self.logger.error(\"Role or content is missing.\")\n",
    "            return\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    @retry(stop_max_attempt_number=7, wait_exponential_multiplier=1000, wait_exponential_max=10000)\n",
    "    def __call__(self, user_input : str = 'hi'):\n",
    "        if not user_input:\n",
    "            self.logger.error(\"User input is missing.\")\n",
    "            return\n",
    "        self.add_message(\"user\", user_input)\n",
    "        try:\n",
    "            self.response = openai.ChatCompletion.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to query the model: {e}\")\n",
    "            return None\n",
    "        self.add_message(\"assistant\", self.get_response_content())  # save the assistant's response\n",
    "        return self.get_response_content()\n",
    "\n",
    "    def get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            self.logger.warning(\"Response is empty.\")\n",
    "            return None\n",
    "\n",
    "    def get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response[\"choices\"][0][\"finish_reason\"]\n",
    "        else:\n",
    "            self.logger.warning(\"Response is empty.\")\n",
    "            return None\n",
    "    \n",
    "    def print_history(self):\n",
    "        for message in self.messages:\n",
    "            role = message[\"role\"]\n",
    "            content = message[\"content\"]\n",
    "\n",
    "            if role == \"user\":\n",
    "                formatted_message = colored(\"User : \", attrs=[\"bold\"]) + content\n",
    "            elif role == \"assistant\":\n",
    "                formatted_message = colored(\"Assistant : \", attrs=[\"bold\"]) + colored(content, \"green\", \"on_dark_grey\")\n",
    "            else:\n",
    "                #formatted_message = content  # System message, no formatting\n",
    "                continue\n",
    "\n",
    "            print(formatted_message)\n",
    "            print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current president of South Korea, as of my latest update, is Moon Jae-in. He assumed office on May 10, 2017. However, I recommend checking the latest sources to make sure the information is still current.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptchat = GPTChatClass(role_msg = 'You are a helpful assistant.')\n",
    "gptchat(user_input = 'hi')\n",
    "# Assitant : Hello! How can I assist you today?\n",
    "gptchat(user_input = 'Who is the current korean president?')\n",
    "# Assitant : The current president of South Korea, as of 2022, is Moon Jae-in. He has been in office since May 10, 2017."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUser : \u001b[0mhi\n",
      "==================================================\n",
      "\u001b[1mAssistant : \u001b[0m\u001b[100m\u001b[32mHello! How can I assist you today?\u001b[0m\n",
      "==================================================\n",
      "\u001b[1mUser : \u001b[0mWho is the current korean president?\n",
      "==================================================\n",
      "\u001b[1mAssistant : \u001b[0m\u001b[100m\u001b[32mThe current president of South Korea, as of my latest update, is Moon Jae-in. He assumed office on May 10, 2017. However, I recommend checking the latest sources to make sure the information is still current.\u001b[0m\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "gptchat.print_history()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make GPT use Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert.preprocessors.execute import CellExecutionError\n",
    "\n",
    "# Create a new notebook\n",
    "nb = nbformat.v4.new_notebook()\n",
    "\n",
    "# Add a cell with your code\n",
    "code_str = \"\"\"\n",
    "import sys\n",
    "\n",
    "print('hi)\n",
    "\"\"\"\n",
    "code_cell = nbformat.v4.new_code_cell(source=code_str)\n",
    "nb.cells.append(code_cell)\n",
    "\n",
    "# Execute the notebook\n",
    "ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "output_str, error_str =None,None\n",
    "try:\n",
    "    ep.preprocess(nb)\n",
    "    output = nb.cells[0].outputs[0]\n",
    "    #print(output)\n",
    "    output_str = output['text']\n",
    "except CellExecutionError as e:\n",
    "    error_str = e\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Error Message* cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----[ERROR]-----\n",
      "\n",
      "  Cell In[1], line 3\n",
      "    print('hi)\n",
      "          ^\n",
      "SyntaxError: unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "if error_str is not None:\n",
    "    # Get the traceback, which is a list of strings, and join them into one string\n",
    "    filtered_error_msg = error_str.__str__().split('An error occurred while executing the following cell')[-1].split(\"\\n------------------\\n\")[-1]\n",
    "    raw_error_msg = \"\".join(filtered_error_msg)\n",
    "    \n",
    "    # Remove escape sequences for colored text\n",
    "    error_msg = raw_error_msg.replace(\"\\x1b[0m\", \"\").replace(\"\\x1b[0;31m\", \"\").replace(\"\\x1b[0;32m\", \"\").replace(\"\\x1b[1;32m\", \"\").replace(\"\\x1b[38;5;241m\", \"\").replace(\"\\x1b[38;5;28;01m\", \"\").replace(\"\\x1b[38;5;21m\", \"\").replace(\"\\x1b[38;5;28m\", \"\").replace(\"\\x1b[43m\", \"\").replace(\"\\x1b[49m\", \"\").replace(\"\\x1b[38;5;241;43m\", \"\").replace(\"\\x1b[39;49m\", \"\").replace(\"\\x1b[0;36m\", \"\")\n",
    "    error_lines = error_msg.split(\"\\n\")\n",
    "    \n",
    "    # Only keep the lines up to (and including) the first line that contains 'Error' followed by a ':'\n",
    "    error_lines = error_lines[:next(i for i, line in enumerate(error_lines) if 'Error:' in line) + 1]\n",
    "\n",
    "    # Join the lines back into a single string\n",
    "    error_msg = \"\\n\".join(error_lines)\n",
    "    \n",
    "    print('-----[ERROR]-----')\n",
    "    print(error_msg)\n",
    "else:\n",
    "    print('-----[OUTPUT]-----')\n",
    "    print(output_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
